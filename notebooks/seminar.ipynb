{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lhrn5O-qUYZ"
   },
   "source": [
    "# Import and misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "meO-Mp9jiAFC",
    "outputId": "b81351fe-e4ec-4de2-b080-fc0725f3ba71"
   },
   "outputs": [],
   "source": [
    "# Instal latest torch and torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bbUpoArCqUYa"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, Union, List, Callable, Optional\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "import pathlib\n",
    "import dataclasses\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torchaudio\n",
    "from IPython import display as display_\n",
    "\n",
    "# Set working dir to project root\n",
    "while not os.getcwd().endswith(\"hw2_kws\"):\n",
    "    os.chdir(os.pardir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "812GwLfqqUYf"
   },
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1DuQIyRqUYf"
   },
   "source": [
    "In this notebook we will implement a model for finding a keyword in a stream.\n",
    "\n",
    "We will implement the version with CRNN because it is easy and improves the model. \n",
    "(from https://www.dropbox.com/s/22ah2ba7dug6pzw/KWS_Attention.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8PdhApeEh9pH"
   },
   "outputs": [],
   "source": [
    "from src.configs import TaskConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KA1gPmE1h9pI"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2N8zcx9MF1X",
    "outputId": "7f8235e9-e2dd-4e33-cabe-07b92c0f2c36"
   },
   "outputs": [],
   "source": [
    "# !wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz -O speech_commands_v0.01.tar.gz\n",
    "# !mkdir speech_commands && tar -C speech_commands -xvzf speech_commands_v0.01.tar.gz 1> log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "12wBTK0mNUsG"
   },
   "outputs": [],
   "source": [
    "class SpeechCommandDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        transform: Optional[Callable] = None,\n",
    "        path2dir: str = None,\n",
    "        keywords: Union[str, List[str]] = None,\n",
    "        csv: Optional[pd.DataFrame] = None\n",
    "    ):        \n",
    "        self.transform = transform\n",
    "\n",
    "        if csv is None:\n",
    "            path2dir = pathlib.Path(path2dir)\n",
    "            keywords = keywords if isinstance(keywords, list) else [keywords]\n",
    "            \n",
    "            all_keywords = [\n",
    "                p.stem for p in path2dir.glob('*')\n",
    "                if p.is_dir() and not p.stem.startswith('_')\n",
    "            ]\n",
    "\n",
    "            triplets = []\n",
    "            for keyword in all_keywords:\n",
    "                paths = (path2dir / keyword).rglob('*.wav')\n",
    "                if keyword in keywords:\n",
    "                    for path2wav in paths:\n",
    "                        triplets.append((path2wav.as_posix(), keyword, 1))\n",
    "                else:\n",
    "                    for path2wav in paths:\n",
    "                        triplets.append((path2wav.as_posix(), keyword, 0))\n",
    "            \n",
    "            self.csv = pd.DataFrame(\n",
    "                triplets,\n",
    "                columns=['path', 'keyword', 'label']\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            self.csv = csv\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        instance = self.csv.iloc[index]\n",
    "\n",
    "        path2wav = instance['path']\n",
    "        wav, sr = torchaudio.load(path2wav)\n",
    "        wav = wav.sum(dim=0)\n",
    "        \n",
    "        if self.transform:\n",
    "            wav = self.transform(wav)\n",
    "\n",
    "        return {\n",
    "            'wav': wav,\n",
    "            'keywors': instance['keyword'],\n",
    "            'label': instance['label']\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-1rVkT81Pk90"
   },
   "outputs": [],
   "source": [
    "datadir = 'C:/Users/foma/Downloads/'\n",
    "\n",
    "dataset = SpeechCommandDataset(\n",
    "    path2dir=datadir + 'speech_commands', keywords=TaskConfig.keyword\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "DFwhAXdfQLIA",
    "outputId": "ce911e31-70e4-43d9-d5f0-5eca0e4776fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>keyword</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16381</th>\n",
       "      <td>C:/Users/foma/Downloads/speech_commands/go/014...</td>\n",
       "      <td>go</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45617</th>\n",
       "      <td>C:/Users/foma/Downloads/speech_commands/six/70...</td>\n",
       "      <td>six</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52857</th>\n",
       "      <td>C:/Users/foma/Downloads/speech_commands/tree/a...</td>\n",
       "      <td>tree</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47100</th>\n",
       "      <td>C:/Users/foma/Downloads/speech_commands/stop/0...</td>\n",
       "      <td>stop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56546</th>\n",
       "      <td>C:/Users/foma/Downloads/speech_commands/up/4c7...</td>\n",
       "      <td>up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path keyword  label\n",
       "16381  C:/Users/foma/Downloads/speech_commands/go/014...      go      0\n",
       "45617  C:/Users/foma/Downloads/speech_commands/six/70...     six      0\n",
       "52857  C:/Users/foma/Downloads/speech_commands/tree/a...    tree      0\n",
       "47100  C:/Users/foma/Downloads/speech_commands/stop/0...    stop      0\n",
       "56546  C:/Users/foma/Downloads/speech_commands/up/4c7...      up      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.csv.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUxfDJw1qUYi"
   },
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dkmkxPWQqUYe"
   },
   "outputs": [],
   "source": [
    "class AugsCreation:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.background_noises = [\n",
    "            'speech_commands/_background_noise_/white_noise.wav',\n",
    "            'speech_commands/_background_noise_/dude_miaowing.wav',\n",
    "            'speech_commands/_background_noise_/doing_the_dishes.wav',\n",
    "            'speech_commands/_background_noise_/exercise_bike.wav',\n",
    "            'speech_commands/_background_noise_/pink_noise.wav',\n",
    "            'speech_commands/_background_noise_/running_tap.wav'\n",
    "        ]\n",
    "\n",
    "        self.noises = [\n",
    "            torchaudio.load(datadir + p)[0].squeeze()\n",
    "            for p in self.background_noises\n",
    "        ]\n",
    "\n",
    "    def add_rand_noise(self, audio):\n",
    "\n",
    "        # randomly choose noise\n",
    "        noise_num = torch.randint(low=0, high=len(\n",
    "            self.background_noises), size=(1,)).item()\n",
    "        noise = self.noises[noise_num]\n",
    "\n",
    "        noise_level = torch.Tensor([1])  # [0, 40]\n",
    "\n",
    "        noise_energy = torch.norm(noise)\n",
    "        audio_energy = torch.norm(audio)\n",
    "        alpha = (audio_energy / noise_energy) * \\\n",
    "            torch.pow(10, -noise_level / 20)\n",
    "\n",
    "        start = torch.randint(\n",
    "            low=0,\n",
    "            high=max(int(noise.size(0) - audio.size(0) - 1), 1),\n",
    "            size=(1,)\n",
    "        ).item()\n",
    "        noise_sample = noise[start: start + audio.size(0)]\n",
    "\n",
    "        audio_new = audio + alpha * noise_sample\n",
    "        audio_new.clamp_(-1, 1)\n",
    "        return audio_new\n",
    "\n",
    "    def __call__(self, wav):\n",
    "        aug_num = torch.randint(low=0, high=4, size=(1,)).item()   # choose 1 random aug from augs\n",
    "        augs = [\n",
    "            lambda x: x,\n",
    "            lambda x: (x + distributions.Normal(0, 0.01).sample(x.size())).clamp_(-1, 1),\n",
    "            lambda x: torchaudio.transforms.Vol(.25)(x),\n",
    "            lambda x: self.add_rand_noise(x)\n",
    "        ]\n",
    "\n",
    "        return augs[aug_num](wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ClWThxyYh9pM"
   },
   "outputs": [],
   "source": [
    "indexes = torch.randperm(len(dataset))\n",
    "train_indexes = indexes[:int(len(dataset) * 0.8)]\n",
    "val_indexes = indexes[int(len(dataset) * 0.8):]\n",
    "\n",
    "train_df = dataset.csv.iloc[train_indexes].reset_index(drop=True)\n",
    "val_df = dataset.csv.iloc[val_indexes].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PDPLht5fqUYe"
   },
   "outputs": [],
   "source": [
    "# Sample is a dict of utt, word and label\n",
    "train_set = SpeechCommandDataset(csv=train_df, transform=AugsCreation())\n",
    "val_set = SpeechCommandDataset(csv=val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vbPDqd6qUYj"
   },
   "source": [
    "### Sampler for oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rfnjRKo2qUYj"
   },
   "outputs": [],
   "source": [
    "# We should provide to WeightedRandomSampler _weight for every sample_; by default it is 1/len(target)\n",
    "\n",
    "def get_sampler(target):\n",
    "    class_sample_count = np.array(\n",
    "        [len(np.where(target == t)[0]) for t in np.unique(target)])   # for every class count it's number of occ.\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in target])\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    samples_weigth = samples_weight.float()\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UM8gLmHeqUYj"
   },
   "outputs": [],
   "source": [
    "train_sampler = get_sampler(train_set.csv['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lyBqbxp0h9pO"
   },
   "outputs": [],
   "source": [
    "class Collator:\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        wavs = []\n",
    "        labels = []    \n",
    "\n",
    "        for el in data:\n",
    "            wavs.append(el['wav'])\n",
    "            labels.append(el['label'])\n",
    "\n",
    "        # torch.nn.utils.rnn.pad_sequence takes list(Tensors) and returns padded (with 0.0) Tensor\n",
    "        wavs = pad_sequence(wavs, batch_first=True)    \n",
    "        labels = torch.Tensor(labels).long()\n",
    "        return wavs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8G9xPRVqUYk"
   },
   "source": [
    "###  Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6wGBMcQiqUYk"
   },
   "outputs": [],
   "source": [
    "# Here we are obliged to use shuffle=False because of our sampler with randomness inside.\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=TaskConfig.batch_size,\n",
    "                          shuffle=False, collate_fn=Collator(),\n",
    "                          sampler=train_sampler,\n",
    "                          pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=TaskConfig.batch_size,\n",
    "                        shuffle=False, collate_fn=Collator(),\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTlsn6cpqUYk"
   },
   "source": [
    "### Creating MelSpecs on GPU for speeeed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pRXMt6it56fW"
   },
   "outputs": [],
   "source": [
    "class LogMelspec:\n",
    "\n",
    "    def __init__(self, is_train, config):\n",
    "        # with augmentations\n",
    "        if is_train:\n",
    "            self.melspec = nn.Sequential(\n",
    "                torchaudio.transforms.MelSpectrogram(\n",
    "                    sample_rate=config.sample_rate,\n",
    "                    n_fft=400,\n",
    "                    win_length=400,\n",
    "                    hop_length=160,\n",
    "                    n_mels=config.n_mels\n",
    "                ),\n",
    "                torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "                torchaudio.transforms.TimeMasking(time_mask_param=35),\n",
    "            ).to(config.device)\n",
    "\n",
    "        # no augmentations\n",
    "        else:\n",
    "            self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "                sample_rate=config.sample_rate,\n",
    "                n_fft=400,\n",
    "                win_length=400,\n",
    "                hop_length=160,\n",
    "                n_mels=config.n_mels\n",
    "            ).to(config.device)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # already on device\n",
    "        return torch.log(self.melspec(batch).clamp_(min=1e-9, max=1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Pqkz4_gn8BiF"
   },
   "outputs": [],
   "source": [
    "melspec_train = LogMelspec(is_train=True, config=TaskConfig(device=torch.device(\"cpu\")))\n",
    "melspec_val = LogMelspec(is_train=False, config=TaskConfig(device=torch.device(\"cpu\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoAxmihY8yxr"
   },
   "source": [
    "### Quality measurment functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "euwD1UyuqUYk"
   },
   "outputs": [],
   "source": [
    "# FA - true: 0, model: 1\n",
    "# FR - true: 1, model: 0\n",
    "\n",
    "def count_FA_FR(preds, labels):\n",
    "    FA = torch.sum(preds[labels == 0])\n",
    "    FR = torch.sum(labels[preds == 0])\n",
    "    \n",
    "    # torch.numel - returns total number of elements in tensor\n",
    "    return FA.item() / torch.numel(preds), FR.item() / torch.numel(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YHBUrkT1qUYk"
   },
   "outputs": [],
   "source": [
    "def get_au_fa_fr(probs, labels):\n",
    "    sorted_probs, _ = torch.sort(probs)\n",
    "    sorted_probs = torch.cat((torch.Tensor([0]), sorted_probs, torch.Tensor([1])))\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "        \n",
    "    FAs, FRs = [], []\n",
    "    for prob in sorted_probs:\n",
    "        preds = (probs >= prob) * 1\n",
    "        FA, FR = count_FA_FR(preds, labels)        \n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "    # plt.plot(FAs, FRs)\n",
    "    # plt.show()\n",
    "\n",
    "    # ~ area under curve using trapezoidal rule\n",
    "    return -np.trapz(FRs, x=FAs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcEP5cEZqUYl"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cP_pFIsy5p2",
    "outputId": "1af690bf-bba6-4033-84e7-b400d37c846b"
   },
   "outputs": [],
   "source": [
    "from src.models import CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DmmSFvWaqUYn"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, loader, log_melspec, device):\n",
    "    model.train()\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader), total=len(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # run model # with autocast():\n",
    "        logits = model(batch)\n",
    "        # we need probabilities so we use softmax & CE separately\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UIeRbn4tqUYo"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation(model, loader, log_melspec, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_losses, accs, FAs, FRs = [], [], [], []\n",
    "    all_probs, all_labels = [], []\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        output = model(batch)\n",
    "        # we need probabilities so we use softmax & CE separately\n",
    "        probs = F.softmax(output, dim=-1)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        all_probs.append(probs[:, 1].cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        val_losses.append(loss.item())\n",
    "        accs.append(\n",
    "            torch.sum(argmax_probs == labels).item() /  # ???\n",
    "            torch.numel(argmax_probs)\n",
    "        )\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "\n",
    "    # area under FA/FR curve for whole loader\n",
    "    au_fa_fr = get_au_fa_fr(torch.cat(all_probs, dim=0).cpu(), all_labels)\n",
    "    return au_fa_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "PpyvKwp0k3IU"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSNW-nZCJ4Q0"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8sVpHNoocgA",
    "outputId": "f72cf20f-0877-4be9-8b6a-789086928b6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
      "    (1): Flatten(start_dim=1, end_dim=2)\n",
      "  )\n",
      "  (gru): GRU(144, 32, num_layers=2, batch_first=True, dropout=0.1)\n",
      "  (attention): Attention(\n",
      "    (energy): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "config = TaskConfig(device=torch.device(\"cpu\"))\n",
    "model = CRNN(config).to(config.device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "opt = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=config.weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zedXm9dmINAE",
    "outputId": "35174419-43cb-4690-fa8a-773abca4f9cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25387"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Fix random generators seed.\n",
    "\n",
    "    Args:\n",
    "        seed (int): random seed\n",
    "\n",
    "    \"\"\"\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END OF EPOCH 19\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "history = defaultdict(list)\n",
    "for n in range(TaskConfig.num_epochs):\n",
    "\n",
    "    train_epoch(model, opt, train_loader,\n",
    "                melspec_train, config.device)\n",
    "\n",
    "    au_fa_fr = validation(model, val_loader,\n",
    "                          melspec_val, config.device)\n",
    "    history['val_metric'].append(au_fa_fr)\n",
    "    \n",
    "    if n == 0 or au_fa_fr < min(history['val_metric'][:-1]):\n",
    "        model_path = f\"resources/checkpoints/crnn_epoch{n}.pth\"\n",
    "        model_dir = os.path.dirname(model_path)\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    clear_output()\n",
    "    plt.plot(history['val_metric'])\n",
    "    plt.ylabel('Metric')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    print('END OF EPOCH', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBkTUHZcVugz",
    "outputId": "94e0c5a2-d1ed-4f7b-8691-069bb2aabfd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'val_metric': [0.000764120597572312,\n",
       "              0.0003859451722614663,\n",
       "              0.00022199277001772809,\n",
       "              0.00016406578564777952,\n",
       "              0.0001503284911160373,\n",
       "              0.0001154004351237319,\n",
       "              0.00011269713606948376,\n",
       "              8.02993202515739e-05,\n",
       "              9.91388679651752e-05,\n",
       "              8.876130272160451e-05,\n",
       "              6.674701969484646e-05,\n",
       "              6.808375035301774e-05,\n",
       "              8.650556973594049e-05,\n",
       "              7.141960945086478e-05,\n",
       "              6.117929780165991e-05,\n",
       "              7.096607583469953e-05,\n",
       "              4.862954523856092e-05,\n",
       "              5.703781978036143e-05,\n",
       "              5.373776596800111e-05,\n",
       "              4.861164259581755e-05]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1guSqniIfz54"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seminar.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
